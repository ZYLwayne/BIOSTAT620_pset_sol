---
title: Problem set 6
date: 2025-03-02
execute: 
  eval: true
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(error = TRUE)
```
For this problem set we want you to predict the 2024 election. You you will report a prediction of the number of electoral votes for Harris and an interval. You will do the same for the popular vote. You will compare your accuracy to the true results.

1. Read in the data provided here:

```{r}
url <- "https://raw.githubusercontent.com/dmcable/BIOSTAT620/refs/heads/main/data/president_polls.csv"
```

Examine the data frame paying particular attention to the `poll_id` `question_id`, `population`, and `candidate`. Note that some polls have more than one question based on different population types.

```{r}
library(tidyverse)
library(rvest)

# Read data from provided URL
url <- "https://raw.githubusercontent.com/dmcable/BIOSTAT620/refs/heads/main/data/president_polls.csv"
raw_dat <- read_csv(url)

# Check first few rows
glimpse(raw_dat)

raw_dat %>%
  count(candidate_name, sort = TRUE)

raw_dat %>%
  count(population, sort = TRUE)

```

2. Polls are based on either likely voters (lv), registered voters (rv), all voters (a), or voters (v).
Polls based on 'voters' are exit polls. We want to remove these because exit polls are too old or might be biased due to differences in the likelihood of early voter by party.  We prefer likely voter (lv) polls because they are more predictive. Registered voter polls are more predictive than all voter (a) polls. Remove the exit poll (v) polls and then redefine `population` to be a factor ordered from best to worse predictive power: (lv, rv, a). You should also remove hypothetical polls and make the date columns into date objects. Name the resulting data frame `dat`.

```{r}
dat <- raw_dat %>%
  
  filter(population != "v") %>%
  # Remove hypothetical polls
  filter(!hypothetical) %>%
  # Convert date columns and set population as an ordered factor
  mutate(
    start_date = as.Date(start_date, format = "%m/%d/%y"),
    end_date = as.Date(end_date, format = "%m/%d/%y"),
    population = factor(population, levels = c("lv", "rv", "a"), ordered = TRUE)
  )


glimpse(dat)


```


3. Some polls asked more than one questions. So if you filter to one poll ID in our dataset, you might see more than one question ID associated with the same poll. The most common reason for this is that they asked a head-to-head question (Harris versus Trump) and, in the same poll, a question about all candidates. We want to prioritize the head-to-head questions.

Add a column that tells us, for each question, how many candidates where mentioned in that question.

Add a new column `n` to `dat` that provides the number of candidates mentioned for each question.  For example
the relevant column of your final table will looks something like this:

|`poll_id`|`question_id`|`candidate`|`n`|
---------|-------------|-----------|--|
1 | 1 | Harris | 2 |
1 | 1 | Trump | 2 |
1 | 2 | Harris | 3 |
1 | 2 | Trump |  3 |
1 | 2 | Stein |3 |

```{r}
library(dplyr)

dat <- dat %>%
  group_by(poll_id, question_id) %>%
  mutate(n = n()) %>%
  ungroup()

glimpse(dat)
```


4. We are going to focus on the Harris versus Trump comparison. Redefine `dat` to only include the rows providing information for Harris and Trump. Then pivot the dataset so that the percentages for Harris and Trump are in their own columns. Note that for pivot to work you will have to remove some columns. To avoid this keep only the columns you are pivoting and along with `poll_id`, `question_id`, `state`, `pollster`, `start_date`, `end_date`, `numeric_grade`, `sample_size`.  Once you accomplish the pivot, add a column called `spread` with the difference between Harris and Trump. 

Note that the values stored in `spread` are estimates of the popular vote difference that we will use to predict: 

**spread = % of the popular vote for Harris - % of the popular vote for Trump**

However, for the calculations in the rest of problem set to be consistent with the sampling model we have been discussing in class, save `spread` as a proportion, not a percentage. But remember to turn it back to a percentage when reporting your answer.

```{r}
library(tidyverse)
dat <- dat %>%
  filter(candidate_name %in% c("Kamala Harris", "Donald Trump")) %>%
  # Select relevant columns
  select(
    poll_id, question_id, state, pollster, start_date, end_date, 
    numeric_grade, sample_size, population, candidate_name, pct, n
  ) %>%
  # Convert candidate names into separate columns
  pivot_wider(names_from = candidate_name, values_from = pct) %>%
  # Compute the spread (percentage point difference between Harris and Trump)
  mutate(spread = (`Kamala Harris` - `Donald Trump`) / 100)


glimpse(dat)



```

5. Note that some polls have multiple questions. We want to keep only one question per poll. We will keep likely voter (lv) polls when available, and prefer register voter (rv) over all voter polls (a). If more than one question was asked in one poll, take the most targeted question (smallest `n`). Save the resulting table`dat`. Note that now each after you do this each row will represents exactly one poll/question, so can remove `n`, `poll_id` and `question_id`.

```{r}
library(dplyr)


if (!"population" %in% colnames(dat)) {
  dat <- dat |> 
    left_join(select(population_dat, poll_id, question_id, population), 
              by = c("poll_id", "question_id"))
}

dat <- dat |> 
  arrange(poll_id, question_id) |>  
  group_by(poll_id) |> 
  mutate(priority = case_when(
    population == "lv" ~ 1,  
    population == "rv" ~ 2,  
    population == "a"  ~ 3,  
    TRUE ~ 4
  )) |> 
  filter(priority == min(priority, na.rm = TRUE)) |>  
  filter(question_id == min(question_id, na.rm = TRUE)) |>  
  ungroup()


if ("priority" %in% colnames(dat)) {
  dat <- dat |> select(-priority)
}

glimpse(dat)
```

6. Separate `dat` into two data frames: one with popular vote polls and one with state level polls. Call them `popular_vote` and `polls` respectively. 

```{r}
library(dplyr)
popular_vote <- dat |> 
  filter(is.na(state))  

polls <- dat |> 
  filter(!is.na(state))  


glimpse(popular_vote)
glimpse(polls)
```

7. For the popular vote, plot the spread reported by each poll against start date for polls starting after July 21, 2024. Rename all the pollsters with less than 5 polls during this period as `Other`. Use color to denote pollster. Make separate plots for likely voters and registered voters. Do not use _all voter_ polls (a). Use `geom_smooth` with method `loess` to show a curve going through the points. You can change how adaptive the curve is to that through the `span` argument.

```{r}
library(ggplot2)
library(lubridate)

popular_vote_filtered <- popular_vote |> 
  filter(start_date >= make_date(2024, 7, 21) & population != "a") |> 
  group_by(pollster) |> 
  mutate(pollster = ifelse(n() < 5, "Other", pollster)) |>  
  ungroup()

popular_vote_filtered <- popular_vote_filtered |> 
  mutate(start_date = as.Date(start_date)) |> 
  filter(!is.na(start_date))

popular_vote_filtered <- popular_vote_filtered |> 
  filter(!is.na(spread) & is.finite(spread)) |>
  filter(spread > -30 & spread < 30)

ggplot(popular_vote_filtered |> filter(population == "lv"), 
       aes(x = start_date, y = spread, color = pollster)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE) +  
  scale_x_date(date_labels = "%b %Y") +  
  labs(title = "Popular Vote Trend for Likely Voters",
       x = "Start Date", y = "Spread (Harris - Trump)",
       color = "Pollster") +
  theme_minimal()

ggplot(popular_vote_filtered |> filter(population == "rv"), 
       aes(x = start_date, y = spread, color = pollster)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE) +
  scale_x_date(date_labels = "%b %Y") +  
  labs(title = "Popular Vote Trend for Registered Voters",
       x = "Start Date", y = "Spread (Harris - Trump)",
       color = "Pollster") +
  theme_minimal()

```


8. To show the pollster effect, make boxplots for the the spread for each popular vote poll. Include only likely voter polls starting after July 21, 2024. Rename all the pollsters with less than 5 polls during that time period as `Other`. 

```{r}
library(ggplot2)
library(lubridate)

# Filter for likely voter polls after July 21, 2024
popular_vote_filtered <- popular_vote %>%
  filter(start_date > make_date(2024, 7, 21) & population == "lv") %>%
  group_by(pollster) %>%
  mutate(n_pollster = n()) %>%
  ungroup() %>%
  mutate(pollster = if_else(n_pollster < 5, "Other", pollster))

# Create a boxplot for spread across different pollsters
ggplot(popular_vote_filtered, aes(x = reorder(pollster, spread, median), y = spread * 100)) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.5) +  # Add jittered points for better visibility
  labs(title = "Pollster Effect on Spread (Likely Voters)", 
       x = "Pollster", 
       y = "Spread (%)") +
  theme_minimal() +
  coord_flip()  # Flip axes for better readability

```

9. Compute a prediction and an interval and report the result. Include the code you used to create your confidence interval for the popular vote here:

```{r}
library(tidyverse)

lv_polls <- popular_vote %>%
  filter(start_date > make_date(2024, 7, 21), population == "lv") %>%
  pull(spread)  

t_test_result <- t.test(lv_polls)
prediction_popular <- t_test_result$estimate * 100 
ci_popular <- t_test_result$conf.int * 100  


print(prediction_popular)  
print(ci_popular)          
         
```
Mean and Confidence Interval
The sample mean of the spread, as estimated using a t-test, is 2.664%. This means that, among recent likely voter polls, the average spread between Harris and Trump is approximately 2.66 percentage points in favor of Harris.

The 95% confidence interval for this estimate is [2.41%, 2.92%]. This suggests that we are 95% confident that the true popular vote spread lies within this range.

Harris received a popular vote spread of `-1.5%` vs Trump in the 2024 election. How did your model do? Provide some potential explanations for the performance.

```
In the 2024 election, Harris received an actual popular vote spread of -1.5% relative to Trump. Our model predicted a spread of +2.66% with a confidence interval of [2.41%, 2.92%], which does not include the actual result (-1.5%). This indicates that the model overestimated Harris’s performance by approximately 4.16 percentage points.
This significant overestimation of Harris's support could be attributed to several factors, including:Polling Bias; Turnout Differences; Weighting Issues.
```

We now move on to predicting the electoral votes.

10. To obtain the number of electoral votes for each state we will visit this website:

```{r}
url <- "https://state.1keydata.com/state-electoral-votes.php"
```

We can use the **rvest** package to download and extract the relevant table:

```{r}
library(rvest)
h <- read_html(url) |>
  html_table() 

ev <- h[[4]]
```

Wrangle the data in `ev` to only have two columns `state` and `electoral_votes`. Make sure the electoral vote column is numeric. Add the electoral votes for Maine CD-1 (1), Maine CD-2 (1), Nebraska CD-2 (1), and District of Columbia (3) by hand. 

```{r}
library(rvest)
url_ev <- "https://state.1keydata.com/state-electoral-votes.php"
h <- read_html(url_ev) %>% html_table()
ev <- h[[4]] %>% 
  rename(state = X2, electoral_votes = X3) %>%  
  select(state, electoral_votes) %>%
  mutate(electoral_votes = as.numeric(electoral_votes)) %>%
  add_row(state = "Maine CD-1", electoral_votes = 1) %>%
  add_row(state = "Maine CD-2", electoral_votes = 1) %>%
  add_row(state = "Nebraska CD-2", electoral_votes = 1) %>%
  add_row(state = "District of Columbia", electoral_votes = 3)

```

11. The presidential race in some states is a forgone conclusion. Because their is practically no uncertainty in who will win, polls are not taken. We will therefore assume that the party that won in 2020 will win again in 2024 if no polls are being collected for a state.

Download the following sheet:

```{r}
library(gsheet)
sheet_url <- "https://docs.google.com/spreadsheets/d/1D-edaVHTnZNhVU840EPUhz3Cgd7m39Urx7HM8Pq6Pus/edit?gid=29622862"
raw_res_2020 <- gsheet2tbl(sheet_url) 
```

Tidy the `raw_res_2020` dataset so that you have two columns `state` and `party`, with `D` and `R` in the party column to indicate who won in 2020. Add Maine CD-1 (D), Maine CD-2 (R), Nebraska CD-2 (D), and District of Columbia (D) by hand. Save the result to `res_2020`. Hint use the **janitor** `row_to_names` function.

```{r}
library(gsheet)
sheet_url <- "https://docs.google.com/spreadsheets/d/1D-edaVHTnZNhVU840EPUhz3Cgd7m39Urx7HM8Pq6Pus/edit?gid=29622862"
raw_res_2020 <- gsheet2tbl(sheet_url)

library(dplyr)
library(janitor)
raw_res_2020 <- raw_res_2020 %>% row_to_names(row_number = 1)
raw_res_2020 <- raw_res_2020 %>% clean_names()

res_2020 <- raw_res_2020 %>%
  select(state, biden_joe_democratic, trump_donald_republican) %>%
  mutate(
    biden = as.numeric(biden_joe_democratic),
    trump = as.numeric(trump_donald_republican),
    party = if_else(biden > trump, "D", "R")
  ) %>%
  select(state, party)

res_2020 <- res_2020 %>%
  add_row(state = "Maine CD-1", party = "D") %>%
  add_row(state = "Maine CD-2", party = "R") %>%
  add_row(state = "Nebraska CD-2", party = "D") %>%
  add_row(state = "District of Columbia", party = "D")

print(res_2020)
```

12. Decide on a period that you will use to compute your prediction. We will use `spread` as the outcome. Make sure the the outcomes is saved as a proportion not percentage. Create a `results` data frame with columns `state`, `avg`, `sd`, `n` and `electoral_votes`, with one row per state. 

Some ideas and recommendations:

* If a state has enough polls, consider a short period, such as a week. For states with few polls you might need to increase the interval to increase the number of polls.
* Decide which polls to prioritize based on the `population` and `numeric_grade` columns.
* You might want to weigh them differently, in which you might also consider using `sample_size`.
* If you use fewer than 5 polls to calculate an average, your estimate of the standard deviation (SD) may be unreliable. With only one poll, you wont be able to estimate the SD at all. In these cases, consider using the SD from similar states to avoid unusual or inaccurate estimates.


```{r}
results <- polls %>%
  filter(start_date > make_date(2024, 7, 21)) %>%
  group_by(state) %>%
  summarise(avg = mean(spread),
            sd = if_else(n() > 1, sd(spread), NA_real_),
            n = n()) %>%
  left_join(ev, by = "state")

```


13. Note you will not have polls for all states. Assume that lack of polls implies the state is not in play.
Use the `res_2020` data frame to compute the electoral votes Harris is practically guaranteed to have.

```{r}
harris_start <- res_2020 %>%
  filter(party == "D") %>%
  left_join(ev, by = "state") %>% 
  summarise(total = sum(electoral_votes, na.rm = TRUE)) %>% 
  pull(total)

print(harris_start)
```


14. Use a Bayesian approach to compute posterior means and standard deviations for each state in `results`. Plot the posterior mean versus the observed average with the size of the point proportional to the number of polls.

```{r}
library(ggplot2)


prior_mean <- median(results$avg, na.rm = TRUE)
prior_n <- 5  

results <- results %>%
  mutate(posterior_mean = (n * avg + prior_n * prior_mean) / (n + prior_n))  


ggplot(results, aes(x = avg * 100, y = posterior_mean * 100, size = n)) +
  geom_point(alpha = 0.6) +  # 添加散点图
  labs(title = "Posterior Mean vs Observed Average (State-Level)",
       x = "Observed Average Spread (%)",
       y = "Posterior Mean Spread (%)",
       size = "Number of Polls") +
  theme_minimal()
```


15. Compute a prediction and an interval for Harris' electoral votes and show the result. Include the code you used to create your estimate and interval below. 

```{r}
results <- results %>%
  mutate(predicted_win = if_else(posterior_mean > 0, electoral_votes, 0))

predicted_ev <- sum(results$predicted_win, na.rm = TRUE)

results <- results %>%
  mutate(var = if_else(!is.na(sd) & n > 1, (sd^2) / n, 0))
total_variance <- sum(results$var, na.rm = TRUE)
se_total <- sqrt(total_variance)

# 95% Confidence interval
ci_ev <- c(predicted_ev - 1.96 * se_total, predicted_ev + 1.96 * se_total)

cat("Predicted Electoral Votes for Harris:", round(predicted_ev), "\n")
ci_ev
```

Harris received 226 electoral votes in the 2024 election. How did your model do? Provide some potential explanations for the performance.

```
My model predicted that Harris would receive 264 electoral votes with a 95% confidence interval of [263.75, 264.25], but the actual result was only 226 votes, suggesting that the model overestimated Harris' support.
The reasons for this could be 1. My prediction is based on recent polling data, which may be systematically biased. For example, voters failed to vote according to polling preferences (e.g., swing voters ultimately chose Trump).
2. Voter turnout misjudgement: my model does not take into account the effect of actual voter turnout.
3. The model assumptions may be overly optimistic; my model uses Bayesian adjustment to calculate the posterior mean, but may not adequately account for election uncertainty.

```